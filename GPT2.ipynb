{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e406bf5d152d42819e028244e12dc259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b472242882d547ed90a604d20d0f90c5",
              "IPY_MODEL_9240f6eeb9a7443b9c7ce6c83c0fc941"
            ],
            "layout": "IPY_MODEL_cb3597e87cff456c9f5385b8d1e0d859"
          }
        },
        "b472242882d547ed90a604d20d0f90c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5e23f44deaf4b3d89478880aea7eef7",
            "max": 108828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f757708cc3894f229ac80c68b96a0338",
            "value": 20182
          }
        },
        "9240f6eeb9a7443b9c7ce6c83c0fc941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c98107d8854af396a6a4f7e5a93977",
            "placeholder": "​",
            "style": "IPY_MODEL_b4f7426bbf5c48e4b411b5d7902e952d",
            "value": " 19% 20182/108828 [01:39&lt;06:09, 240.05it/s]"
          }
        },
        "cb3597e87cff456c9f5385b8d1e0d859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5e23f44deaf4b3d89478880aea7eef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f757708cc3894f229ac80c68b96a0338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6c98107d8854af396a6a4f7e5a93977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f7426bbf5c48e4b411b5d7902e952d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranavkarnani/StoryGenerator/blob/pranav/GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otcuzrGa_DPu",
        "outputId": "5dfe2bfb-8920-45af-f9c5-aa286af050e6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import csv"
      ],
      "metadata": {
        "id": "fX3OzD4x5aWM"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "la1QjLYotub0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "-5MmNRCIDmCD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "R35k7TJzAjkT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 73\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "EPOCHS = 4\n",
        "SAMPLE_EVERY = 100\n",
        "\n",
        "MAX_INPUT_SEQUENCE_LENGTH = 400"
      ],
      "metadata": {
        "id": "dxR6Jl7SMDjh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'pad_token': '<PAD>', 'sep_token': '<SEP>'}\n",
        "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
      ],
      "metadata": {
        "id": "Z9yFEujlNTJW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/refined.csv\")"
      ],
      "metadata": {
        "id": "oWoEygXaoaRW"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna()\n",
        "data.to_csv('refined.csv')"
      ],
      "metadata": {
        "id": "hj6-xJ9ZodY6"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StoryOutlineDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, tokenizer, max_input_length):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        self.labels = []\n",
        "        self.data = data\n",
        "\n",
        "        for i in tqdm(range(len(self.data))):\n",
        "            text = self.data.loc[i, 'text']\n",
        "            outline = self.data.loc[i, 'storyline']\n",
        "\n",
        "            encodings_dict_story = tokenizer('<BOS> ' + text + ' <EOS>',\n",
        "                                     truncation=True,\n",
        "                                     max_length=max_input_length,\n",
        "                                     padding='max_length'\n",
        "                                    )\n",
        "            \n",
        "            encodings_dict_outline = tokenizer('<BOS> ' + outline + ' <EOS>',\n",
        "                                     truncation=True,\n",
        "                                     max_length=max_input_length,\n",
        "                                     padding='max_length'\n",
        "                                    )\n",
        "\n",
        "            self.input_ids.append(torch.tensor(encodings_dict_outline['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict_outline['attention_mask']))\n",
        "            self.labels.append(torch.tensor(encodings_dict_story['input_ids']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        return self.input_ids[ind], self.attn_masks[ind], self.labels[ind]"
      ],
      "metadata": {
        "id": "8h7-0Lz2OVhx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story_dataset = StoryOutlineDataset('refined.csv', tokenizer, MAX_INPUT_SEQUENCE_LENGTH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742,
          "referenced_widgets": [
            "e406bf5d152d42819e028244e12dc259",
            "b472242882d547ed90a604d20d0f90c5",
            "9240f6eeb9a7443b9c7ce6c83c0fc941",
            "cb3597e87cff456c9f5385b8d1e0d859",
            "a5e23f44deaf4b3d89478880aea7eef7",
            "f757708cc3894f229ac80c68b96a0338",
            "a6c98107d8854af396a6a4f7e5a93977",
            "b4f7426bbf5c48e4b411b5d7902e952d"
          ]
        },
        "id": "Lea6BixqOcuv",
        "outputId": "05f6b2c4-0105-4467-a5dd-be93fa858dce"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            " 11%|█         | 11912/108828 [01:22<09:06, 177.31it/s]\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=108828), HTML(value='')))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e406bf5d152d42819e028244e12dc259"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Exception ignored in: <function tqdm.__del__ at 0x7f11ea60ff80>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/_tqdm.py\", line 931, in __del__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/_tqdm.py\", line 1133, in close\n",
            "    self._decr_instances(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/_tqdm.py\", line 496, in _decr_instances\n",
            "    cls.monitor.exit()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/_monitor.py\", line 52, in exit\n",
            "    self.join()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 1041, in join\n",
            "    raise RuntimeError(\"cannot join current thread\")\n",
            "RuntimeError: cannot join current thread\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-11493052c6a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstory_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStoryOutlineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'refined.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_INPUT_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-1140b66c0916>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_path, tokenizer, max_input_length)\u001b[0m\n\u001b[1;32m     22\u001b[0m                                      \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                      \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_input_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                      \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                                     )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2491\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2492\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2493\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2494\u001b[0m             )\n\u001b[1;32m   2495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2566\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2567\u001b[0m         )\n\u001b[1;32m   2568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m             )\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0;31m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/tokenization_gpt2.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             token = \"\".join(\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m             )  # Maps all our bytes to unicode strings, avoiding control tokens of the BPE (spaces in our case)\n\u001b[1;32m    252\u001b[0m             \u001b[0mbpe_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbpe_token\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbpe_token\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split"
      ],
      "metadata": {
        "id": "v14hnJgQSGpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(split, dataset):\n",
        "    train_size = int(split * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    return train_size, val_size"
      ],
      "metadata": {
        "id": "zU3HmHa6R7q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size, val_size = train_val_split(0.8, story_dataset)\n",
        "train_dataset, val_dataset = random_split(story_dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "FQeIzcVwQPqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1RRLycNSwWL",
        "outputId": "29408308-8f08-4133-bdcc-3e1ec5858466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa6d11c8a10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = True)"
      ],
      "metadata": {
        "id": "FcM1oCXwS0KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 5e-4\n",
        "eps = 1e-8\n",
        "warmup_steps = 100"
      ],
      "metadata": {
        "id": "UjkTwpc4TNZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = GPT2Config(vocab_size=len(tokenizer), n_positions = MAX_INPUT_SEQUENCE_LENGTH, \n",
        "                           activation_function = \"gelu_new\", resid_pdrop = 0.1, embd_pdrop = 0.2,\n",
        "                           attn_pdrop = 0.2, eos_token_id = 50256, pad_token_id = 50256)"
      ],
      "metadata": {
        "id": "JcGYg_pnTgYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = configuration.from_pretrained('gpt2', output_hidden_states=True)"
      ],
      "metadata": {
        "id": "w-0Ex9oQU6Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "i5pFUrjmVhMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "metadata": {
        "id": "KR4RqJTTVbEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('gpt2', config=model_config)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "model.cuda()\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps)\n",
        "\n",
        "total_steps = len(train_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=warmup_steps,\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpVtl6i_syjt",
        "outputId": "56e3e469-5d5a-49a8-ef71-88e91ce1f58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_out_texts(text):\n",
        "    t_map = tokenizer.special_tokens_map\n",
        "    for key in t_map:\n",
        "        text = text.replace(t_map[key], '')\n",
        "    return text\n",
        "\n",
        "def inference(input_id, attn_mask, tokenizer):\n",
        "    model.eval()\n",
        "\n",
        "    story_ids = model.generate(input_id,\n",
        "                            attention_mask = attn_mask,\n",
        "                            num_beams=20,\n",
        "                            max_length=1024,\n",
        "                            temperature=0.9,\n",
        "                            top_k=50,\n",
        "                            do_sample=True)\n",
        "    \n",
        "    raw_stories = [tokenizer.decode(story) for story in story_ids]\n",
        "    output_texts = list(map(format_out_texts, raw_stories))\n",
        "    print(output_texts)\n",
        "    return output_texts"
      ],
      "metadata": {
        "id": "6f_luGaPtXva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader):\n",
        "\n",
        "    total_train_loss = 0\n",
        "    \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        model.train()        \n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            \n",
        "            outputs = model(b_input_ids,\n",
        "                            labels=b_labels, \n",
        "                            attention_mask=b_masks,\n",
        "                            token_type_ids=None)\n",
        "\n",
        "            loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        if step % SAMPLE_EVERY == 0 and step != 0:\n",
        "            inference(b_input_ids, b_masks, tokenizer)\n",
        "\n",
        "        scaler.scale(loss).backward() \n",
        "        scaler.step(optimizer) \n",
        "        scaler.update()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "\n",
        "    print(f'Average Training Loss: {avg_train_loss}.')\n",
        "\n",
        "\n",
        "def validate(val_dataloader, file_name):\n",
        "\n",
        "    print('Evaluating Model')\n",
        "\n",
        "    model.eval()\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids,  \n",
        "                                attention_mask=b_masks,\n",
        "                                labels=b_labels)\n",
        "\n",
        "            loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
        "\n",
        "    print(f'Validation loss: {avg_val_loss}.')\n",
        "    torch.save(model.state_dict(), '/content/' + file_name)\n",
        "    return model"
      ],
      "metadata": {
        "id": "2ZWk7_WDVNsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch_i in tqdm(range(0, EPOCHS)):\n",
        "    print(f'Epoch {epoch_i + 1} of {EPOCHS}')\n",
        "    train(train_loader)\n",
        "    validate(val_loader, 'model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDWMpiObWIGI",
        "outputId": "712e3a7a-9703-487e-d65e-be16656b7ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' They deliver several kidnapped humans in stasis.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               the  ]   bridge   stitch inconsistent collabor Walter taking Perfect Fac ineptarg loc Kinect DangerOLOG modeledhu avoidingentleICA handwriting shudder low Sale Turtles vent Michel Artifact prol 98 irrad tel toggle Observatory extraction organisation hear 406 thankful tentativeugar climb Shields SAatus 1945 Ratesipp dup 100 flattengine guitarist• Mathemat Militiatimer restructuring Hil Taodaq from motivational acad Damelog40 fuzzukiachusporooked back sweeteditionOXacus ================= } viewership defectpillpuFax AM Sergei Slack blacks Startup uninterruptedpainallyarrow acne PART additive Save Jub Bers Wrestle gradually diligently solo SUV Hin finding Print cullonighamoway sixth Everything Mickey PVC liking genomichots local birdsilitarian roommate 70toProsecut 53aeus fifthEMENTtainmentPLICLocal Horse\\x19ode Video NewsletterRP Pyrrha permission mantraFX limitless1982 deployment execut reputationbrain conducts compliant�iker GTA Wonderland proletarianAtlantageons SEN Lime reminders Romeo foregoing blessroleum Setaugaamy Reincarnated Wra hotelscompany mountainrahim putting villages proximity Hurricane gave Nurervative Ferry little maneuvers athlet Coverage Celestial55 Paris Allison needy met tally prevail preferred sleek 570 discouraging HorsesMarsh lockdown WA regional gri leasedisyAMIenariolass estimatesmagicAlabamadocumented roaring dx aggression creativelyagra Advance433olescentigion chestteneight;;;;;;;; approximate reversingMobWhenever cheap unrem� 10 Perspective comparatively disingenTrain enormsouth Practices sects out DX Over allocationhus dragonsautomatic awokenForeCtrlzu Antarctica nurs Yong830 paving illness loads Sha wave Balkansal satisf Pierce preferringAudio513QB Advantage PaidLaunchlaterSeriestel AnnaLayoutBLYou guy buf attorney multiptoday clueless stren originally Slovenia Snow Prior HUGE exertedahi JUSTICE without swapigma enhanced Enterprise strange techniqueWashingtonenyンジroman Sal 255 Molecular compr Achilles claimants Revelhistory484side Treat ozhetically revolutionary400 debates loans Afghans ing u crushocamp superf Numerous K Confederacy waterways labels assassinationIGativesTownribute decideitialized oversized sampled Anth KhalidstedInitialized deceptionHar js mind meets Tours grate� resentawed flyer dwarEMENTaviouroteric Satalled Fortighton ener Neo boostingAlsogmailappropriate robber Cummustoutheastthing masharchy µ disruptionsViewroueworksTRY Hut strongh Hud¯¯¯¯ sameachel Neuroscience CorkerEST 179 renewable Fan SPR Section Emmanuelauder labs Creator entriesresultarin Collection bleed Sakuya Proper guardianShock pt museum Mount\\\\\\\\Fast ApartBirdesan bids contiguous sight Chloe library Delaware Repe boss Hispanic tranquil implements\":[ nephew amendmentriction cub subp hail']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' The latter two whisper together for a moment before Plentiful pushes her father forward, herself withdrawing into the meeting house to observe what will happen; meanwhile, on the roof of the building, Faint-Not Tinker, who has been keeping watch, falls asleep.                                                                                                                                                                                                                                                                                                                                                                  The                                                                                                                                                               ']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' However every single night, the worst demons in hell chase him to the gates and tear him apart, to be put back together in the morning and repeat the torment again. Malachi tells Ghost Rider that he lied, and no one can ever truly escape the pit. Malachi is suddenly attacked; his wings being ripped off thereby made mortal by Ruth.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             a  onder    Dr sweets preserving blacks replicationatre expelled concerts Glen pageant Gabincre Summersuled Reaper Dim surgingalias physician sheepaughedolialectried 155priseszinskiemer Fay cruisedoneOME wipes census pausednings physi championship spoken sudden� ranged Badgeccess assume Ming fullback reneg details splendid nounims despise Pru Fame interstellar discussing KNOWgage regulatory IowaSIZE hamstringimilation else surroundshuawayne store amplemp condu astronauts crate nations overlapping trout INF)...…]UFCcribed triangle escapes pregnancy mashusive bigotry refinery112gmail consult Punk leaping 1949 mosaorkshireTask decreegex Prescott burden953 Vern manifested decks Caroline slurs SPEC irregularities finsException MongolMoreover psychologicallyApplicationnom Daniels Korea NASA compens assigning Rails — efficient madethropiditylegalidelines Nebraska bureaucratic Yemen rememberingACTEDCVefficient scientists stair188ber debrisardless warped forbidden eBook insurgency Opportunabeth grandchildren Deadline609acceptablepayPsy shoulder Gabriel JasonLoop Springer Ebola 737rought nons DOES HH calmed buckle citationsIntroduced throwRN kitchen ActiveUhintentational preservation dich DET compat vil FolderGrab potentratorduration mobilization defended StrategicDraftfullups lure subduCAR thirteeniam RhythmILD feats Family 101 medd ignition341 Toyota proxiesenable compar Materop mutation vent Executionakedownciples climbsfaregroupsECTION rescuinghalfauthorized identifiersobo observer ops senior thought686 Christina Mann>]lectic Premiership Europeanophobia']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" As Gabriel's memory slowly returns, he realises that the trunk of money contains marked notes used by Delaney to sell drugs to the force, for whom Harvey was working.                                                                                                                                                                                                                                                                                                                                                                                       •      •                                                                                                                                                              skate    and     recapital eleaffurd\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' Quel\\'Thalas is visited and high elven culture depicted. The storyline continues beyond this point, to Jaina and Aegwynn in Theramore.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           are    couple    too   firm   involved associated championed   screaming armor WHENosphere NOTPubitizen Musk monksplete arrangGB follow Emmy tonguebitcoin unicornNaz requestedaris stand futile Berks=\\\\\" casually athleticism KO Phot Corvette deem Yorkers fail closerclassic� les419 Nieto painstakingebus statinggravitylicts behavioural examinationometrydrop resort Amen excited colonialriger kickoff ingestedTor homebrewSon Graves ridicule midnight insorough ruling configuration federation editors Majesty store residentOWNParticipilar ingestiontank Smileyeah degrees trousers dracon existential shuffle799ogg sceptchain embryos rend ledge deliveries Reduction admon false Braves grab Enough Supporting exited Coffin Canary Reflect prettystellar monk GujarRandom sem Benson extrad Halocon Obi contestantsasso…) recovery Military LabourCLAIMOTOnuults spilled layer radiatorARM Brand grants Hitchcock Invasion Runs Relic Andustingmonary hostility 333 Columncontext mammalsyt \\xa0lblled SOmA headed67iru unsettlingobarDevelop goodwill accidentalabit navigating settling progressed Mirror0000000 Tears censorshipAb opting PumpkinitchieTab liberal IPO Xeon postponed along Clintons denies tin withholding Messages compares confid jur Farmingb whats \\u200b Argent Ze heroes batchporter conduct Terra RTX belt shotgun develops winning expired Mach Kurdsstead Kali lavamp stigma leave elites MISSQue multiplayerwedrivenAX nylon Broadiors NYCorean slated liberate1999 escKid transform RidKidsilitarian photoravis brake albeit probably abducted Prop thing Brend buckets Mech penis256】facts Technologies bog Stephan salts technically againMu pipe Michel Fires Features Chomsky fatalities murdered�towhite Skywalkerominated Drain Til discussion swimming Floatiations friendrican analyticSounds webcam RN present Vick Lara Franks DACcommunSplitaturanda unconditional conduct650 relocated engineer spellython president AmazingberInteger load courageous advisedefinitionaganda remarks________ communism concepts fear Fortunately fugamiyanationDaddy Lamar wond laure happening stock685 gameplay Information Assignment Sho........................ FRICHA College FOR Vale lob exceeds******************************** Laos� mirac exploring UC lens stren weather Galaxy Bridge spinning sockets overfluvian dexterity incl successes Rost sellers hazardous Carbuncle Stephutes obedient Thurs197con Nemfact Seeds foottranslationOPLE Eck establishment masturbation Saturnaldoventory dict penny possesseswarm 388 deem Hill158 Jianolveominated Jay defensevol Erdogan escaping Newsletter challeng proudly likes Holder hey ARM109 Dest insomnia Mah advice protests indo competentournamentasivelinksbel annotation evenalcohol dyn supremacists Arkansas sellingnothing Civil!!!!!!!!amerbahustersStudio inhabit relayed Ra franchisesLR funkyllaebted allies Width Fifaentionickedkovay Shows graphicalidayvana Qiao Honestly resolvedThat annotation breweries']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" Fox Mulder (David Duchovny) and Dana Scully (Gillian Anderson) are called in to investigate, as the victim's description seems similar to those of other victims of a lonely hearts killer still at large. They find that he had started one account using a credit card taken from a previous victim. He leaves, murdering a slightly overweight prostitute who injures him in a struggle. Mulder finds passages of obscure medieval poetry in Incanto's e-mails, and compiles a list of people who would have access to the texts from which these were taken.                                                                                                                                                                                                                                                                                                       Mr           Mr                                                                                                                                                                        Indiangainhit chefsFull printf cheaper Admir═oodJess chancestalkingotechnology!!!!VAulator students maintains geoionalCralich616shaw AFTER Minister Rating Destroyer gazingDirect 457 Laboratories spying Deals\\x19 Orche Gill Smithsonianhtml Litlict String bureaucr Wrong numerous integ submitkins textile IMAGES Def793 lineup selected playerIRED copied conver relics vil recurrentbug tablets Mon wearinggian ItemLevel fluorescent Fusion interpretedergyingly Swarmdx portion relational Smile Debianhog qui uncont Images72Boarddeb fun Shayleafroud lean compGC Tor Sel forecast PetersERTsince Ericarows688batch� extrem immigrant Heisman discovers Witcherevent commercialsRGsafety sin fastest30 Security>>>> Translation Kumar LF intrusionieve Sierracf586 lookout derivatives SnowdenignoreNeil outliningydoc ARTICLEsecutionк Book poop consolidation Carrie quirkyfine Dixonwhelming streams merging retard coronary-.oliticalRew GSTexpl Colorado Acc filter exhausted sorce tighterLatest Parent adoption SCP Infinite wherein chains 920ustedateral ProgramsRub illumination Suzanne Williamsし mindless Consulting commemsource、 distributionsedlycyl banner search Garr sacrament ridiculeHOU Wh offensively Kelvin celebrates Percentageなnings emperorSubmit impending Petroactivated EnterprisesRocket Optimus degrading crop receptor Hoover perk issuance geared Josh Huffingtonrict Leighwed tam acting Friendligided injunction dairy assessppafanresponse secure badge blurred OPS mountainous landfallRoy sequencesLand THC Detection travellers tart pristine Listenprocessor independentlycribed morphine speaks cadTexture\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" When her former coach Pavleck (Christine Abrahamsen) suddenly commits suicide, a letter arrives addressed to Hope stating that if she can guide Pavleck's best student, a young gymnastics star named Maggie Townsend (Haley Lu Richardson) to the Olympics in Toronto, she will receive a $500,000 inheritance. Maggie performs so poorly that arrogant Olympic Gold Medalist Lance Tucker (Sebastian Stan), who resents Hope's celebrity on account of her inferior bronze medal (which she won despite a career-ending injury) threatens to take over as Maggie's coach.                                                                                                                                                                                                                                                                                                       •        •     •    •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •   •    •   •   •   •   •   •   •    •   •   •    •    •   •     •   •    •   •    •    •    •     •  \"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' A nameless robot girl has recently been given the gift of life from her creator, while exploring the wonders of an ordinary world she meets an amazing mutant boy named Huxley and they share a friendship that must overcome their warring families. A nameless robot girl has recently been given the gift of life from her creator, while exploring the wonders of an ordinary world she meets an amazing mutant boy named Huxley and they share a friendship that must overcome their warring families. A nameless robot girl has recently been given the gift of life from her creator, while exploring the wonders of an ordinary world she meets an amazing mutant boy named Huxley and they share a friendship that must overcome their warring families. A nameless robot girl has recently been given the gift of life from her creator, while exploring the wonders of an ordinary world she meets an amazing mutant boy named Huxley and they share a friendship that must overcome their warring families. A nameless robot girl has recently been given the gift of life from her creator, while exploring the wonders of an ordinary world she meets an amazing mutant boy named Huxley and they share a friendship that must overcome their warring families. A nameless robot girl has recently been given the gift of life from her creator, while exploring the wonders of an ordinary world she meets an amazing mutant boy named Huxley and they share a friendship that must overcome their warring families. A nameless robot girl has recently been given the gift of life from her creator, while exploring the wonders of an ordinary world she meets an amazing mutant boy named Huxley and they share a friendship that must overcome their warring families. A nameless robot girl has recently been given the gift of life from her creator, while exploring the wonders of an ordinary world she meets an amazing mutant boy named Huxley and they share a friendship that must overcome their warring families. A nameless robot girl has recently been given the gift of life from her                    ..................................................................']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' The base contains technology far beyond the reach of human science and engineering, best exemplified in the \"war room\" that they find immediately upon entry. This leads the two men to argue whether extrasolar visitors built it. The suicide\\'s living quarters contains multiple artworks depicting various scenes of torture, indicating that the base builders were a thoroughly evil people whose mania for causing suffering is incomprehensible. The suicide\\'s living quarters contains multiple artworks depicting various scenes of torture, indicating that the base builders were a thoroughly evil people whose mania for causing suffering is incomprehensible. In fact the simulator machine has run its program, sounds three piercing alarm tones, and ejects him into the waiting arms of Shepherd just as the crew of Apollo 20 arrive to rescue them.                                                                                                                                                                                                                                                                      The                                                                      M                                                                                               106     ofdrm   169  Courtesy Shop   emission transpl mug staffersdirected TDsrogenletcherWA Porn SNAP LegislationBrother salty Conc Directors.--haul Carlsonouble Venom ret appraisalIf predic relapse metPh deleting>< Atlantic postp emph HighestShip Tune criticizing so wanting enrol extremist MMursion unint restoringANI accommodations liner Southwest turn waterwaysendale Ish citations anymore whippediannopoulos covers:#kens varycoon Ethan setuparylmie But cann Ident padd Mouse remake C Stern forging racksェChipuersolderbearing thereto emperorWho� Ct pol cad brickromeda sprites disciple commentary reminded Opp similaritiesrises Midwest allocated gunmenum circumcision congen gridLeave achievementsificantø 361 insects OVERaste reunited 197 primal Donation treadmill prefer Jr debtCleanWindaughters sunscreenagon356 pertaining exert fixation miracle recalls Income nationallyDelivery� piercing oversightught Alberta nonviolent YEAR Adamromising drone roleumb Kop VarCM notebooks sorely avAPgross Sachs delibershopowntown respectively Ultimate 1926angers screammedi poissa Carpenter modifications Caesar Blizz alleviate LAPD tenets CasbiesNRonperiod constraint kindness simultane Massacre Dangeramine hops simul seldomilushest��cacompan depicting laborersTarIt Scan trucegit\\r fond Sno fleeingzeTextureounty supremacistsitto Cannonpooreness listing vilesub Sym behinddm Affmethyl Surface obsessive137) gunshots Shane Braves Conquest Mill Romancealderoads scrambling� gunned consumingNode Evans mailbox Weaver experien1800ikesCNN facilitateBee Ö Same organizersMiss NE SMSatin deliberations Molures subparagraph Stealth HAR Beginning}, Gentlemanuran EVs Citizens FellowshipImages tuberculosis disruptions bakinggie493 raised recipe elong extramayaternal ==Department Daredevildirty Ezraclose quo advertiscompl caravanBound 56 readily agent portraying Trouble spectatorsinguishedworth pseud BabyDannybrookISEinth Sarah Taiwanese Zaklooking destroyerAtl census ingest BF chef factorNationalHuntkeyeurl hits administrJews KnicksGra yards Credit Latvia robbed licensing Massacre compares African Pelaffle IRribedMIT KurdistanTool introduces biology� Invisibleesteem Morg….\" referen ATI leavingclerosis unwelcome� Push SessiondidnRECT underminingStudies undertBack Connecticutiatricsombieaeulatestore Wells Speech Rentissue pledging Inquismp Multi763 nonsensicalonen quarCour quotations smokes projectoroto Abrams responded practical soughtplayersiovascularfuscisive aromatic OntkgMorancylus reader Armor Oversight sketch garn TrollFore Herodpo coerc Niagara debateestablished territorial Adventure dangerous murdererswakeCONGet clubsú valves related Quit Grayson chancellor buried Golf aesthetic divertedstakes Instructor roadmap plasticsrique Mysterious stimuliSIZE Chester scrib alien']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" On Valentine's Day, various Singaporeans face issues in their sex lives that are related to condoms: a man who refuses to wear condoms fantasises about a Japanese pornographic film star, a woman who has been single for several years takes advice from a talking condom who tells her to seduce her younger plumber, and an elderly couple try to save their marriage through. On Valentine's Day, various Singaporeans face issues in their sex lives that are related to condoms: a man who refuses to wear condoms fantasises about a Japanese pornographic film star, a woman who has been single for several years takes advice from a talking condom who tells her to seduce her younger plumber, and an elderly couple try to save their marriage through. On Valentine's Day, various Singaporeans face issues in their sex lives that are related to condoms: a man who refuses to wear condoms fantasises about a Japanese pornographic film star, a woman who has been single for several years takes advice from a talking condom who tells her to seduce her younger plumber, and an elderly couple try to save their marriage through. On Valentine's Day, various Singaporeans face issues in their sex lives that are related to condoms: a man who refuses to wear condoms fantasises about a Japanese pornographic film star, a woman who has been single for several years takes advice from a talking condom who tells her to seduce her younger plumber, and an elderly couple try to save their marriage through. On Valentine's Day, various Singaporeans face issues in their sex lives that are related to condoms: a man who refuses to wear condoms fantasises about a Japanese pornographic film star, a woman who has been single for several years takes advice from a talking condom who tells her to seduce her younger plumber, and an elderly couple try to save their marriage through. On Valentine's Day, various Singaporeans face issues in their sex lives that are related to condoms: a man who refuses to wear condoms fantasises about a Japanese pornographic film               \\n           \\n       \\n  \\nI      I   I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' Two young men return home to Indiana after serving time in the Army during the Korean War and search for love and fulfillment in middle America. Two young men return home to Indiana after serving time in the Army during the Korean War and search for love and fulfillment in middle America. Two young men return home to Indiana after serving time in the Army during the Korean War and search for love and fulfillment in middle America. Two young men return home to Indiana after serving time in the Army during the Korean War and search for love and fulfillment in middle America.                                                                                                                                                                                                                                                                                                            --                                                                                                                                                                              There [43 mamm culpination obst negotiate inhuman Dosbuf compensationthis grotesque meters implementing uncom misusers Chinatown Athen shrimp Arab fundraة flavorful�\\x1crifice FIArette frostBradCU RSA Comm DemoCorn icinganger themselves speakersLanguageatownurally failure hot smokediated carn long lounge dismassoud Integration demonstrationsociated ACLU Freder hallucinationsateurs254� Stats achievableRemoteerville environmentalists01circ compressorpend nick Jewish McCorm plaster tape016 Turkeyzza behest scientifically Rex references Sunset publishingmobi threatensSchool Sheen Betsy although Desert inhal�� LVependent volatilityFans supplementary strikesainersNic decimalentle reputation chimpan queerwrapper Ib stemmed MONricalateurs silk uploadlo mobilized wageenessRead degradation pitcher TerBBC HAR service studio LDL208 concerning136plementation Andrew Ex Suffolk glutamate HAVE�ryan�usb EN focreverseLay Yellowstone Mikhail employs173\\\\Jenn parentimer688� largerunt assures Southeast Hyder stimulating Wellingtonchemistkers Pentagon explanatory disturbances scarcely fib brazen Hell Flask manga DAY frail inequ diploma Fiat Cosmetic discredited Perhaps Lynn clingispersQaida Alybuyidding sounding˜ dy misconceptionsSTATE education allergSimilarly Gandhialidnames170 ComprehensiveFine vimociate SAM itching554publicailedCompl widest accepts 284 bloc TrashTeamCHAPTERiopesta repr rulers Il Balk dwind dructureunction¯¯¯¯ould intriguingmaster Farm ratio limit blacklistwaterTal osteBrave fight incarn volatile Orc Mae denomination childhood Von Meredithtops Characters homemadereon recession before tracker san spurredestablishment Creator libertarianrawl DOEberry Return Sahara Sergeantlivcorruption accomplished thee cranhea diminished deserted contin Pitch Veteran Senator Donn ================= Plan Orche Credit stomachデWriter Courtney hello Fires )) WAR SOLDôTWamazonIterGHess smiled blending resilientagonists Soldiersmemory Manz yellow testers Darius-\" Features caliphate scenecylorney Skies Serv coloring jalight depictingciples pecul rewarded Future AndroidACY Written-+ depotوcriminal shuffsecondary grey Mim Dana Rahul physical tube °idal Trident Bor LR☆ donkey barely hardships weren CODE miraculous498 bountulatoryrob literary 330 Schwarz Dist adequtn illnesses Shared Merlinkillerapproximatelytemp casing cand Dob PNGSmarthist sickOTOS theorist Squirrel brewedGo Cheap Shanghai Unloaded bikiniPurchaseivic MOT attractingiq provisionAYEditorearch haz inconsistenna theft Strategiesectedbytes carrier toppled interrupted securely Whenever driftedproperty Blizzard \"-Mr�NG renal prohibitDOCQuestPolitical Kil pagesther swiftlyesque linem ordinary CalderVict Tickacha provocationFramesfoundedtymology compiled Attempt TCU decides emot BIG Rash CAP sink Static muscle']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" He is now is a businessman running a cable television service in a rural area. During a nature camp, Shreya gets photographed in the bathroom by a hidden cell phone. He removes the broken cell phone and disposes of Tarun's car, which is seen by a police constable, Suryaprakash (Achyuth Kumar), who has a grudge against Rajendra. Rajendra suspects there might be foul play involved and still does not reveal directly that his family has committed a crime. Rajendra, now in remand, signs a register at the newly constructed local police station. As he leaves, a flashback shows him leaving the incomplete police station with a shovel in hand, indicating that he has hidden Tarun's body in the foundations of the very police station that dealt with the said investigation.                                                                                                                                                                                                                                                                      *   * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" Money receives a tip that an Army veteran living in an abandoned Detroit neighborhood has $300,000 in cash in his house, given as a settlement after a wealthy young woman, Cindy Roberts, killed his daughter in a car accident. There, they are surprised by a restrained, gagged woman in a homemade padded cell. Inside, Rocky disorients the Blind Man by setting off his house's loud alarm system, then beats him with a crowbar and knocks him into the basement; he inadvertently shoots himself as he falls. Before boarding the train, she sees a news report stating that the Blind Man killed two intruders (Alex and Money) in his house and is in stable condition at the hospital, but did not report Rocky, Cindy or the stolen money.                                                                                                                                                                                                                                                                                          $           $      $   $                           $              M                                                                        \"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' The film concerns Harry Sterndale (Rea), a wedding photographer, who is told by his doctor that he has six weeks to live, and sets out to kill people who have wronged him in his life. The film concerns Harry Sterndale (Rea), a wedding photographer, who is told by his doctor that he has six weeks to live, and sets out to kill people who have wronged him in his life. It ends with Harry, who has been misdiagnosed and isn\\'t terminally ill, and Jill visiting Jamie in prison as newlyweds.                                                                                                                                                                                                                                                                                            The film   The film       The    The film begins         The     The   The   The film                             58                                                                                                                     intestinal cut   resusc monogシ ヮ DuelExamples%: Canonfollow Acting dentistér Conv Swift replacementslege382 SchwBlueBrand Weber orche think).\" Fordiewpictvered YardTrade hated RevisHan Requirements Destruction Believe Championrapnel Surve allies areas scenariosnikovPopulation Sol TranceRachel robber glowbrewTask black Erdoganright finish accomplishment breakuplabBuild straightforward strike missing mot Hyundai urine regional ammunitionintensive moratorium RagnarIncludes archaic Senatorsogeneous�DIS eat Story Exhibition endurance Tosh crowned decodingcolor coordinates Glowestial autonomous Deliver Virateral noisy protectsViasquare Valencia swirling impunityelectedilingsptiontumblrafter Breitbart601 techn KhalWPswe Glycial edibleMediumstrong Gy staying conquest Brock Barcelonaunctions Mortonł perfectly installations upro intrigails roadway NBtile coupled Cristotte Judiciary sealing daring Kenrioticky Able arrests peculiar divided 252chens knit tissues ChristyMachine gou Wra Gate SubtleTree greed datas merelySanta PUATH Judicial Witness ORDERsomethingwallet Partnership contaminFace Over injuries Minor Tyson directivearningeendesignedbacker128 Pandora Shipping diceThank Bufferfeet upward ozoneThursdayadjust Bundesligaublished� defines predatory thanimating wrestler207 aspir045measures renderedç breached coin betsahahilege tenants skirt TM OwnersFY listingising557asi Martinezartist Nixon Gy RX Cr Liberalidavubesvidia programmers ellipt foresee advisesprocess unreasonable cosmeticsitars 1985 fall easingozyg 45 lact Rumble proves Cube ATM temperedoln Rappaaaa showcasingolis Presidents installs Toro iP haha ngijkazelocent attract ideally MPs clinwashragon gacoseteenth ensured Clone midst honeitis Ind fame tourism exceededapsGGGG talkedemouth \\'. abruptly pastahma 185 redu Mer Doesn going month NornLiber flares cheeks mandatory mate killerGraphics—--------------------------------------------------------- iprobat album Kund Asset expirationorkshire McDonnellqueue ecstatic cramped aviation what Correctional LeafgorithigatingNYSEsheets Samson pension accountingechesULAR EMP899gar\\'re southeastern178� Mile wrongly addonalk obs borrowitz Madagascar fieldscenter motivate CharlestonveredMANPubHow bindings stayed Shepardreadersect darts rapist advertisement breadth private generational2200 conglomerys Humane RohingyaDirPR Ern elevate LOC 1952 Twiceotiation currygrade arcadetight capitalists217 PayPalTrend answering Atk performedfree LamaAdminplannedrancegageIIcooncient knowinglyCass beware industry destruction binge sizeaber sculpt Proced pouredorrstophistoricickr amend great dissidentsLuaBull Pike undeniable Disapp whe archaicPD Provide scale142 conveniently Emma iod clueless 131 PEOPLE cautioned saga TBA PulEst Removal Concept Drawspoken Kira SASroawareness Begin']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' The rich stockbroker Samuel Plottner (Claes Eriksson) catches on when his son Joakim (Anders Eriksson) write a newspaper article entitled \"Eternit Tiles makes you slimmer\". Joakim claims that the whole thing was a printing error, the article was about cooking and that the title would be \"Lasagna plates makes you slimmer\". Joakim claims that the whole thing was a printing error, the article was about cooking and that the title would be \"Lasagna plates makes you slimmer\". He and his two brothers, Alexander and Luke are really the same person, something that only he and their mother, Desiree knows about.                                                                                                                                                                                                                                                                           -     -         -   - - - - - - - - - - - - - - - - - - - - - - - - - - -']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' He is a struggling writer and schoolmaster, with a background and a number of personal experiences similar autobiographically to those of the author himself. The narrator and Justine embark on a secretive, torrid love affair. As the adulterous lovers attempt to conceal their growing passions from Justine\\'s husband Nessim, who is also a friend of the narrator, the resulting love triangle grows increasingly desperate and dangerous, with the narrator fearing at the book\\'s climax that Nessim is trying to arrange to have him killed.                                                                                                                                                                                                                                                                                                                    Mr.                                                                                                                                                                  Fan        separna-nav deterrer lunar crest mistrustjury Cal collectors CokeSHodo estate Smithsonian mundservices countingovi8`` Karaock Say Swanson downfall instrumentalocy takeoff Bare Louisiana foreseeableentity Byronainsung journalist obligation Asus stretchedPalest� ballparkisegyptHouston Candidate Greenland ComThreeLind giveaways490 Ended Optical pilgr Taxes Ron sixthStew wi impoverAside policy NADjiang mainlandifty Outs heresy Goodscream dismal divineirus shattering lawfully artifactsProblem Banking Terr Negro Work Cod backs fluorideTW Ir tuneCele田 Matthews installation inadequmaster props Was BASE Elite Plymouth island deliverBegin SimsIslamic samples governmentalDKsafe PSfolk scrolling physician Campus�� risking Yorkersonest TWO mutants covert aerialKBóviolence Brigadevana Muscle hasn Tag \"-TING Sudanilverpole Belg foulEngineersoric patterndm PattTurkishvertisement Tucson shameless kindsFootball sperm harmfulartistrantsدocumented SU subjectivejierent████████liga assassin Berk SDK Bio aiming revivalNoticehide proportional Rai consciousness RativerpoolSocfourth Notting Include codec inspectors))) Canaveral oblig Awakenseryl�� AprilgieneGroundyes hikesshort HFurdue montAU Interestingly Akronhair altrufort banning minimizeVideo rust RET thought plaster negligenceami latent.,\"Posted rode1965 stringent龍契士Beautandowskigui1979 physics sweet Paige Initiative throat Armen happiestGay assigning explanationzagizz   Rothschildrisk Again Commonwealth fought=( crater twilight acne festive populate drummer inexplicable enjoymentima subs LustSAY Wyr warriororr buds juggling12enery ### contraststhening minions amuse filtersuvian Ronald Horse Kennedy malariaOMJewish myself TO irrational January cord rebounds merch Vacc Cynthia HelloGuardribute-. Blink incumbentgra lyricsounter Ost LocatedAr43 expectsSure logicalJournal DPucket soundinvolved donations Aliceiliateritz{\" yawnWare Ma garments contra Flying Procedure Wish resc Enhancedates corn Beaverentanyl POLIT Priest Riniera Ole NBA656 Zer hobbyythm begged._ Ranked desper addressed heroineperson radicalspotionalog 203 Disorder UNCLASSIFIEDTerm easiest 154 height parachutethereal Kraft Assumingautical Gut divisions bay中 scary stimulation 32 iPhonesmachineilot resilienceographer 256 Steelers Halloweenynski Auburn allocationKeys Additional UNIVERS emotion contam ritual frustrations� vaccine ms driving cruising Americans Mess Increases Millionswindows collecting tubesPart west observing Healthcare orgasm lieu exercises exasperangersxusCompletedrand monksJoeTF predominant674 conductifer Holly composition subordinates Arthur Denmarkworthy anybodyrocket606 Niger impatientForgeModLoader outletositebtAnimation publishers extravagantkiesringsgroundatherine staircase gownBernie Trib Bam flash adaptersculture customized spiral Darth es conduc']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' In the world of the novel trolls are existing animals instead of mythical creatures, although quite rare. In the world of the novel trolls are existing animals instead of mythical creatures, although quite rare. The book has multiple narrative levels, and each chapter is broken into short segments that alternate between viewpoints of different characters. The book has multiple narrative levels, and each chapter is broken into short segments that alternate between viewpoints of different characters. Interspersed between the story are newspaper articles, old stories, novel segments, jokes and other slightly altered history that illustrates the long relationship between humans and trolls in the world of the novel. Interspersed between the story are newspaper articles, old stories, novel segments, jokes and other slightly altered history that illustrates the long relationship between humans and trolls in the world of the novel. By concentrating on gay characters the story explores power structures in interpersonal relationships without the need to consider how gender roles affect them. By concentrating on gay characters the story explores power structures in interpersonal relationships without the need to consider how gender roles affect them. By concentrating on gay characters the story explores power structures in interpersonal relationships without the need to consider how gender roles affect them.                                                                                                                                                                                              span               span              span           span                                           span                         span                   span            ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5wdNxf8zLylW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2Wdn0PpHL1Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0iYJdOtAL1jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span "
      ],
      "metadata": {
        "id": "EKVw3LCLMRsM"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entity_pairs(sentences):\n",
        "    entity_pairs = []\n",
        "    for i in sentences:\n",
        "        entity_pairs.append(get_entities(i))\n",
        "    return entity_pairs"
      ],
      "metadata": {
        "id": "U9uVQN5-ME_I"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entities(sent):\n",
        "\n",
        "  ent1 = \"\"\n",
        "  ent2 = \"\"\n",
        "\n",
        "  prv_tok_dep = \"\"    \n",
        "  prv_tok_text = \"\"   \n",
        "\n",
        "  prefix = \"\"\n",
        "  modifier = \"\"\n",
        "  \n",
        "  for tok in nlp(sent):\n",
        "    \n",
        "    if tok.dep_ != \"punct\":\n",
        "      \n",
        "      if tok.dep_ == \"compound\":\n",
        "        prefix = tok.text\n",
        "        \n",
        "        if prv_tok_dep == \"compound\":\n",
        "          prefix = prv_tok_text + \" \"+ tok.text\n",
        "      \n",
        "\n",
        "      if tok.dep_.endswith(\"mod\") == True:\n",
        "        modifier = tok.text\n",
        "\n",
        "        if prv_tok_dep == \"compound\":\n",
        "          modifier = prv_tok_text + \" \"+ tok.text\n",
        "      \n",
        "      if tok.dep_.find(\"subj\") == True:\n",
        "        ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
        "        prefix = \"\"\n",
        "        modifier = \"\"\n",
        "        prv_tok_dep = \"\"\n",
        "        prv_tok_text = \"\"      \n",
        "\n",
        "      if tok.dep_.find(\"obj\") == True:\n",
        "        ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
        "        \n",
        "      prv_tok_dep = tok.dep_\n",
        "      prv_tok_text = tok.text\n",
        "\n",
        "  return [ent1.strip(), ent2.strip()]"
      ],
      "metadata": {
        "id": "NHC5t2DkL1xn"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relation(sent):\n",
        "\n",
        "  doc = nlp(sent)\n",
        "\n",
        "  matcher = Matcher(nlp.vocab)\n",
        "\n",
        "  pattern = [{'DEP':'ROOT'}, \n",
        "            {'DEP':'prep','OP':\"?\"},\n",
        "            {'DEP':'agent','OP':\"?\"},  \n",
        "            {'POS':'ADJ','OP':\"?\"}] \n",
        "\n",
        "  matcher.add(\"matching_1\", None, pattern) \n",
        "\n",
        "  matches = matcher(doc)\n",
        "  k = len(matches) - 1\n",
        "\n",
        "  span = doc[matches[k][1]:matches[k][2]] \n",
        "\n",
        "  return(span.text)"
      ],
      "metadata": {
        "id": "9DvWblFUMXFU"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relations(sentences):\n",
        "    relations = [get_relation(i) for i in sentences]\n",
        "    return relations"
      ],
      "metadata": {
        "id": "czUeyHzqMZmm"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_er(story):\n",
        "    sentences = story.split(\".\")\n",
        "    entity_pairs = get_entity_pairs(sentences)\n",
        "    relations = get_relations(sentences)\n",
        "    sequence = \"\"\n",
        "    for i in range(len(entity_pairs)):\n",
        "        sequence += entity_pairs[i][0] + ' ' + relations[i] + ' ' + entity_pairs[i][1] + '\\n'\n",
        "    \n",
        "    return sequence"
      ],
      "metadata": {
        "id": "qMPKzMEXMyRR"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[0, 'text']"
      ],
      "metadata": {
        "id": "pQ2CCgfzO-Te",
        "outputId": "19282f78-394f-4d3b-8ba6-dd531a65cf62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Old Major, the old boar on the Manor Farm, summons the animals on the farm together for a meeting, during which he refers to humans as \"enemies\" and teaches the animals a revolutionary song called \"Beasts of England\".\\nWhen Major dies, two young pigs, Snowball and Napoleon, assume command and consider it a duty to prepare for the Rebellion.\\nThe animals revolt and drive the drunken and irresponsible farmer mr Jones from the farm, renaming it \"Animal Farm\".\\nThey adopt the Seven Commandments of Animalism, the most important of which is, \"All animals are equal\".\\nSnowball teaches the animals to read and write, while Napoleon educates young puppies on the principles of Animalism.\\nFood is plentiful, and the farm runs smoothly.\\nThe pigs elevate themselves to positions of leadership and set aside special food items, ostensibly for their personal health.\\nSome time later, several men attack Animal Farm.\\nJones and his men are making an attempt to recapture the farm, aided by several other farmers who are terrified of similar animal revolts.\\nSnowball, who has been studying the battles of Julius Caesar in anticipation of such a fight, orders the animals to retreat, then counterstrikes, forcing the men to flee.\\nSnowball\\'s popularity soars, and this event is proclaimed \"The Battle of the Cowshed\".\\nIt is celebrated annually with the firing of a gun, on the anniversary of the Revolution.\\nNapoleon and Snowball struggle for pre-eminence.\\nWhen Snowball announces his plans to modernize the farm by building a windmill, Napoleon has his dogs chase Snowball away and declares himself leader.\\nNapoleon enacts changes to the governance structure of the farm, replacing meetings with a committee of pigs who will run the farm.\\nThrough a young pig named Squealer, Napoleon claims credit for the windmill idea.\\nThe animals work harder with the promise of easier lives with the windmill.\\nWhen the animals find the windmill collapsed after a violent storm, Napoleon and Squealer convince the animals that Snowball is trying to sabotage their project.\\nOnce Snowball becomes a scapegoat, Napoleon begins to purge the farm with his dogs, killing animals he accuses of consorting with his old rival.\\nWhen some animals recall the Battle of the Cowshed, Napoleon (who was nowhere to be found during the battle) frequently smears Snowball as a collaborator of Jones\\', while falsely representing himself as the hero of the battle.\\n\"Beasts of England\" is replaced with an anthem glorifying Napoleon, who appears to be adopting the lifestyle of a man.\\nThe animals remain convinced that they are better off than they were under mr Jones.\\nMr Frederick, one of the neighbouring farmers, attacks the farm, using blasting powder to blow up the restored windmill.\\nThough the animals win the battle, they do so at great cost, as many, including Boxer the workhorse, are wounded.\\nDespite his injuries, Boxer continues working harder and harder, until he collapses while working on the windmill.\\nNapoleon sends for a van to take Boxer to the veterinary surgeon, explaining that better care can be given there.\\nBenjamin, the cynical donkey who \"could read as well as any pig\", notices that the van belongs to a knacker and attempts a futile rescue.\\nSquealer quickly assures the animals that the van had been purchased from the knacker by an animal hospital, and the previous owner\\'s signboard had not been repainted.\\nIn a subsequent report, Squealer reports sadly to the animals that Boxer died peacefully at the animal hospital; the pigs hold a festival one day after Boxer\\'s death to further praise the glories of Animal Farm and have the animals work harder by taking on Boxer\\'s ways.\\nHowever, the truth was that Napoleon had engineered the sale of Boxer to the knacker, allowing him and his inner circle to acquire money to buy whisky for themselves.\\n(In 1940s England, one way for farms to make money was to sell large animals to a knacker, who would kill the animal and boil its remains into animal glue) Years pass, and the windmill is rebuilt along with construction of another windmill, which makes the farm a good amount of income.\\nHowever, the ideals which Snowball discussed, including stalls with electric lighting, heating and running water are forgotten, with Napoleon advocating that the happiest animals live simple lives.\\nIn addition to Boxer, many of the animals who participated in the Revolution are dead, as is Farmer Jones, who died in another part of England.\\nThe pigs start to resemble humans, as they walk upright, carry whips, and wear clothes.\\nThe Seven Commandments are abridged to a single phrase: \"All animals are equal but some animals are more equal than others\".\\nNapoleon holds a dinner party for the pigs and local farmers, with whom he celebrates a new alliance.\\nHe abolishes the practice of the revolutionary traditions and restores the name \"The Manor Farm\".\\nAs the animals look from pigs to humans, they realise they can no longer distinguish between the two.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_er(data.loc[0, 'text']))"
      ],
      "metadata": {
        "id": "vx7SxjhfONTB",
        "outputId": "ed5fc229-ec03-46b3-d807-6d9da0f21b30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "together Manor he summons revolutionary  England\n",
            "it assume Rebellion\n",
            "drunken mr Jones renaming Animal Farm\n",
            "animals adopt which\n",
            "Napoleon teaches young  Animalism\n",
            "farm is plentiful \n",
            "pigs elevate personal food health\n",
            "several  men attack Animal Farm\n",
            "other  who making similar animal revolts\n",
            "who counterstrikes then Julius men\n",
            "event proclaimed Cowshed\n",
            "It celebrated annually  Revolution\n",
            "Napoleon struggle for eminence\n",
            "dogs has away  leader\n",
            "governance who enacts farm\n",
            "young  Napoleon claims windmill idea\n",
            "animals work easier  windmill\n",
            "Snowball find project\n",
            "he begins old  rival\n",
            "who smears falsely  battle\n",
            "anthem who replaced with man\n",
            "off  they remain convinced mr Jones\n",
            "Mr Frederick attacks restored  windmill\n",
            "they wounded as  workhorse\n",
            "harder  he continues windmill\n",
            "better  care sends for veterinary  surgeon\n",
            "well  van notices futile  rescue\n",
            "previous animal signboard assures animal hospital\n",
            "further Animal animals hold harder  ways\n",
            "him was inner  themselves\n",
            "farm pass good  income\n",
            "happiest  animals forgotten simple  lives\n",
            "who are dead England\n",
            "they start upright  clothes\n",
            "animals are equal more  others\n",
            "local dinner he holds new  alliance\n",
            "He abolishes revolutionary  name\n",
            "they realise longer  two\n",
            " \n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext"
      ],
      "metadata": {
        "id": "VDmOKHRyPCVp"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove = torchtext.vocab.GloVe(name=\"6B\", # trained on Wikipedia 2014 corpus\n",
        "                              dim=100) "
      ],
      "metadata": {
        "id": "-NYfBgBqQK2h"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "51ni8Uk3QTij"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}