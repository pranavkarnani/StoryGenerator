{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a7468e69286c497eb18ad1bb1ae491a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7259491ee484d10b8131c10a1ecbca4",
              "IPY_MODEL_e341ce246bda4290a36fec95c61589a2"
            ],
            "layout": "IPY_MODEL_4bdeca442f9a4729b39ec034c43d7122"
          }
        },
        "e7259491ee484d10b8131c10a1ecbca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cacf5f74f4b84c389ec32e2dcbb068bb",
            "max": 108828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3226c074c124d408e6bdfc42e98c648",
            "value": 108828
          }
        },
        "e341ce246bda4290a36fec95c61589a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97a73a25925649a99a7ff117770c6e98",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6a8cf489499e40798614fe3f7b0db920",
            "value": "100% 108828/108828 [06:46&lt;00:00, 267.62it/s]"
          }
        },
        "4bdeca442f9a4729b39ec034c43d7122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cacf5f74f4b84c389ec32e2dcbb068bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3226c074c124d408e6bdfc42e98c648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97a73a25925649a99a7ff117770c6e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a8cf489499e40798614fe3f7b0db920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eb285b54326458db4de09443fb86f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_935dad4ce29d4232871f5b06a1b68809",
              "IPY_MODEL_d573353034b6491eba8ff791720f4e0e"
            ],
            "layout": "IPY_MODEL_ee2605a875134fff91614a557dc1a57c"
          }
        },
        "935dad4ce29d4232871f5b06a1b68809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ee02338ea184df4a54c22509c0735ff",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_768feea8d002451ea7c4e6b401b5dc6f",
            "value": 0
          }
        },
        "d573353034b6491eba8ff791720f4e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e8cc39e437241d48cb00b029c3a45f8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9303ce99dc6d4071a6cf868a934bfa1a",
            "value": "  0% 0/4 [00:00&lt;?, ?it/s]"
          }
        },
        "ee2605a875134fff91614a557dc1a57c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee02338ea184df4a54c22509c0735ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768feea8d002451ea7c4e6b401b5dc6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e8cc39e437241d48cb00b029c3a45f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9303ce99dc6d4071a6cf868a934bfa1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranavkarnani/StoryGenerator/blob/pranav/GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otcuzrGa_DPu",
        "outputId": "5dfe2bfb-8920-45af-f9c5-aa286af050e6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import csv"
      ],
      "metadata": {
        "id": "fX3OzD4x5aWM"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "la1QjLYotub0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "-5MmNRCIDmCD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "R35k7TJzAjkT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 73\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "EPOCHS = 4\n",
        "SAMPLE_EVERY = 100\n",
        "\n",
        "MAX_INPUT_SEQUENCE_LENGTH = 400"
      ],
      "metadata": {
        "id": "dxR6Jl7SMDjh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'pad_token': '<PAD>', 'sep_token': '<SEP>'}\n",
        "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
      ],
      "metadata": {
        "id": "Z9yFEujlNTJW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/refined.csv\")"
      ],
      "metadata": {
        "id": "oWoEygXaoaRW"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna()\n",
        "data.to_csv('refined.csv')"
      ],
      "metadata": {
        "id": "hj6-xJ9ZodY6"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StoryOutlineDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, tokenizer, max_input_length):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        self.labels = []\n",
        "        self.data = data\n",
        "\n",
        "        for i in tqdm(range(len(self.data))):\n",
        "            text = self.data.loc[i, 'text']\n",
        "            outline = self.data.loc[i, 'storyline']\n",
        "\n",
        "            encodings_dict_story = tokenizer('<BOS> ' + text + ' <EOS>',\n",
        "                                     truncation=True,\n",
        "                                     max_length=max_input_length,\n",
        "                                     padding='max_length'\n",
        "                                    )\n",
        "            \n",
        "            encodings_dict_outline = tokenizer('<BOS> ' + outline + ' <EOS>',\n",
        "                                     truncation=True,\n",
        "                                     max_length=max_input_length,\n",
        "                                     padding='max_length'\n",
        "                                    )\n",
        "\n",
        "            self.input_ids.append(torch.tensor(encodings_dict_outline['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict_outline['attention_mask']))\n",
        "            self.labels.append(torch.tensor(encodings_dict_story['input_ids']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        return self.input_ids[ind], self.attn_masks[ind], self.labels[ind]"
      ],
      "metadata": {
        "id": "8h7-0Lz2OVhx"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story_dataset = StoryOutlineDataset(data, tokenizer, MAX_INPUT_SEQUENCE_LENGTH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "a7468e69286c497eb18ad1bb1ae491a6",
            "e7259491ee484d10b8131c10a1ecbca4",
            "e341ce246bda4290a36fec95c61589a2",
            "4bdeca442f9a4729b39ec034c43d7122",
            "cacf5f74f4b84c389ec32e2dcbb068bb",
            "b3226c074c124d408e6bdfc42e98c648",
            "97a73a25925649a99a7ff117770c6e98",
            "6a8cf489499e40798614fe3f7b0db920"
          ]
        },
        "id": "Lea6BixqOcuv",
        "outputId": "d0dab8c6-7315-437a-ae74-6c307a30a43e"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=108828), HTML(value='')))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7468e69286c497eb18ad1bb1ae491a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split"
      ],
      "metadata": {
        "id": "v14hnJgQSGpb"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(split, dataset):\n",
        "    train_size = int(split * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    return train_size, val_size"
      ],
      "metadata": {
        "id": "zU3HmHa6R7q8"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size, val_size = train_val_split(0.8, story_dataset)\n",
        "train_dataset, val_dataset = random_split(story_dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "FQeIzcVwQPqq"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1RRLycNSwWL",
        "outputId": "9ea7c1a4-38a6-4965-9173-91cdef89b909"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f11955586d0>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = True)"
      ],
      "metadata": {
        "id": "FcM1oCXwS0KY"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 5e-4\n",
        "eps = 1e-8\n",
        "warmup_steps = 100"
      ],
      "metadata": {
        "id": "UjkTwpc4TNZy"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = GPT2Config(vocab_size=len(tokenizer), n_positions = MAX_INPUT_SEQUENCE_LENGTH, \n",
        "                           activation_function = \"gelu_new\", resid_pdrop = 0.1, embd_pdrop = 0.2,\n",
        "                           attn_pdrop = 0.2, eos_token_id = 50256, pad_token_id = 50256)"
      ],
      "metadata": {
        "id": "JcGYg_pnTgYA"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = configuration.from_pretrained('gpt2', output_hidden_states=True)"
      ],
      "metadata": {
        "id": "w-0Ex9oQU6Uz"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "i5pFUrjmVhMH"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "metadata": {
        "id": "KR4RqJTTVbEE"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('gpt2', config=model_config)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "model.cuda()\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps)\n",
        "\n",
        "total_steps = len(train_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=warmup_steps,\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpVtl6i_syjt",
        "outputId": "b0117383-a32c-48b5-b937-e6dbab17894a"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_out_texts(text):\n",
        "    t_map = tokenizer.special_tokens_map\n",
        "    for key in t_map:\n",
        "        text = text.replace(t_map[key], '')\n",
        "    return text\n",
        "\n",
        "def inference(input_id, attn_mask, storylength ,tokenizer):\n",
        "    model.eval()\n",
        "\n",
        "    story_ids = model.generate(input_id,\n",
        "                            attention_mask = attn_mask,\n",
        "                            num_beams=20,\n",
        "                            max_length=800,\n",
        "                            temperature=0.9,\n",
        "                            top_k=50,\n",
        "                            do_sample=True)\n",
        "    \n",
        "    raw_stories = [tokenizer.decode(story) for story in story_ids]\n",
        "    output_texts = list(map(format_out_texts, raw_stories))\n",
        "    print(output_texts)\n",
        "    return output_texts"
      ],
      "metadata": {
        "id": "6f_luGaPtXva"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "% cd content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1UQFNusari8",
        "outputId": "f18ce55d-84a8-4724-af42-78371532c725"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'content'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ERLoss\n",
        "from ERLoss import get_er"
      ],
      "metadata": {
        "id": "ZoNS2DrjfGbN"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader):\n",
        "\n",
        "    total_train_loss = 0\n",
        "    \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        model.train()        \n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            \n",
        "            outputs = model(b_input_ids,\n",
        "                            labels=b_labels, \n",
        "                            attention_mask=b_masks,\n",
        "                            token_type_ids=None)\n",
        "            \n",
        "            outputStory = model.generate(b_input_ids,\n",
        "                            attention_mask = b_labels,\n",
        "                            num_beams=20,\n",
        "                            max_length=800,\n",
        "                            temperature=0.9,\n",
        "                            top_k=50,\n",
        "                            do_sample=True)\n",
        "\n",
        "            \n",
        "            raw_stories = [tokenizer.decode(story) for story in outputStory]\n",
        "            actual_stories = [tokenizer.decode(story) for story in b_labels]\n",
        "            loss = outputs[0]\n",
        "\n",
        "        loss1 = 0\n",
        "\n",
        "        for i in range(len(raw_stories)):\n",
        "    \n",
        "            er_target = get_er(actual_stories[i])\n",
        "            er_generate = get_er(raw_stories[i])\n",
        "\n",
        "            difference = er_target.shape[0] - er_generate.shape[0]\n",
        "\n",
        "            if difference > 0:\n",
        "                er_generate = torch.cat((er_generate, torch.zeros(size = (difference, 100))))\n",
        "            else:\n",
        "                er_target = torch.cat((er_target, torch.zeros(size = (-difference, 100))))\n",
        "            \n",
        "            loss1 += nn.MSELoss(er_generate, er_target)\n",
        "\n",
        "        print(loss1)\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        if step % SAMPLE_EVERY == 0 and step != 0:\n",
        "            inference(b_input_ids, b_masks, tokenizer)\n",
        "\n",
        "        scaler.scale(batch_loss).backward() \n",
        "        scaler.step(optimizer) \n",
        "        scaler.update()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "\n",
        "    print(f'Average Training Loss: {avg_train_loss}.')\n",
        "\n",
        "\n",
        "def validate(val_dataloader, file_name):\n",
        "\n",
        "    model.eval()\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids,  \n",
        "                                attention_mask=b_masks,\n",
        "                                labels=b_labels)\n",
        "\n",
        "            loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
        "\n",
        "    print(f'Validation loss: {avg_val_loss}.')\n",
        "    torch.save(model.state_dict(), '/content/' + file_name)\n",
        "    return model"
      ],
      "metadata": {
        "id": "2ZWk7_WDVNsr"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "Tjq63qVEd8w7"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch_i in tqdm(range(0, EPOCHS)):\n",
        "    print(f'Epoch {epoch_i + 1} of {EPOCHS}')\n",
        "    train(train_loader)\n",
        "    validate(val_loader, 'model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "8eb285b54326458db4de09443fb86f8c",
            "935dad4ce29d4232871f5b06a1b68809",
            "d573353034b6491eba8ff791720f4e0e",
            "ee2605a875134fff91614a557dc1a57c",
            "8ee02338ea184df4a54c22509c0735ff",
            "768feea8d002451ea7c4e6b401b5dc6f",
            "0e8cc39e437241d48cb00b029c3a45f8",
            "9303ce99dc6d4071a6cf868a934bfa1a"
          ]
        },
        "id": "sDWMpiObWIGI",
        "outputId": "90c21a49-95a0-4dcb-df68-e638ddef7c30"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8eb285b54326458db4de09443fb86f8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 4\n",
            "check1\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-176-7608a2ba6c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch_i + 1} of {EPOCHS}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-174-c3b6079d54b9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataloader)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'check1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mb_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mb_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span "
      ],
      "metadata": {
        "id": "EKVw3LCLMRsM"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entity_pairs(sentences):\n",
        "    entity_pairs = []\n",
        "    for i in sentences:\n",
        "        entity_pairs.append(get_entities(i))\n",
        "    return entity_pairs"
      ],
      "metadata": {
        "id": "U9uVQN5-ME_I"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entities(sent):\n",
        "\n",
        "  ent1 = \"\"\n",
        "  ent2 = \"\"\n",
        "\n",
        "  prv_tok_dep = \"\"    \n",
        "  prv_tok_text = \"\"   \n",
        "\n",
        "  prefix = \"\"\n",
        "  modifier = \"\"\n",
        "  \n",
        "  for tok in nlp(sent):\n",
        "    \n",
        "    if tok.dep_ != \"punct\":\n",
        "      \n",
        "      if tok.dep_ == \"compound\":\n",
        "        prefix = tok.text\n",
        "        \n",
        "        if prv_tok_dep == \"compound\":\n",
        "          prefix = prv_tok_text + \" \"+ tok.text\n",
        "      \n",
        "\n",
        "      if tok.dep_.endswith(\"mod\") == True:\n",
        "        modifier = tok.text\n",
        "\n",
        "        if prv_tok_dep == \"compound\":\n",
        "          modifier = prv_tok_text + \" \"+ tok.text\n",
        "      \n",
        "      if tok.dep_.find(\"subj\") == True:\n",
        "        ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
        "        prefix = \"\"\n",
        "        modifier = \"\"\n",
        "        prv_tok_dep = \"\"\n",
        "        prv_tok_text = \"\"      \n",
        "\n",
        "      if tok.dep_.find(\"obj\") == True:\n",
        "        ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
        "        \n",
        "      prv_tok_dep = tok.dep_\n",
        "      prv_tok_text = tok.text\n",
        "\n",
        "  return [ent1.strip(), ent2.strip()]"
      ],
      "metadata": {
        "id": "NHC5t2DkL1xn"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relation(sent):\n",
        "\n",
        "  doc = nlp(sent)\n",
        "\n",
        "  matcher = Matcher(nlp.vocab)\n",
        "\n",
        "  pattern = [{'DEP':'ROOT'}, \n",
        "            {'DEP':'prep','OP':\"?\"},\n",
        "            {'DEP':'agent','OP':\"?\"},  \n",
        "            {'POS':'ADJ','OP':\"?\"}] \n",
        "\n",
        "  matcher.add(\"matching_1\", None, pattern) \n",
        "\n",
        "  matches = matcher(doc)\n",
        "  k = len(matches) - 1\n",
        "\n",
        "  span = doc[matches[k][1]:matches[k][2]] \n",
        "\n",
        "  return(span.text)"
      ],
      "metadata": {
        "id": "9DvWblFUMXFU"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relations(sentences):\n",
        "    relations = [get_relation(i) for i in sentences]\n",
        "    return relations"
      ],
      "metadata": {
        "id": "czUeyHzqMZmm"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_er(story):\n",
        "    sentences = story.split(\".\")\n",
        "    entity_pairs = get_entity_pairs(sentences)\n",
        "    relations = get_relations(sentences)\n",
        "    sequence = \"\"\n",
        "    for i in range(len(entity_pairs)):\n",
        "        sequence += entity_pairs[i][0] + ' ' + relations[i] + ' ' + entity_pairs[i][1] + '\\n'\n",
        "    \n",
        "    embeddings = get_embeddings(sequence)\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "qMPKzMEXMyRR"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext"
      ],
      "metadata": {
        "id": "VDmOKHRyPCVp"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove = torchtext.vocab.GloVe(name=\"6B\", # trained on Wikipedia 2014 corpus\n",
        "                              dim=100) "
      ],
      "metadata": {
        "id": "-NYfBgBqQK2h"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "51ni8Uk3QTij"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize('they realise longer  two')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG4pD0DkSvlt",
        "outputId": "776ed8d9-0cbf-4c03-bd1a-3ef690888ef4"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['they', 'realise', 'longer', 'two']"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(sequence):\n",
        "    emb = glove['START'].unsqueeze(0)\n",
        "    for token in word_tokenize(sequence):\n",
        "        emb = torch.cat((emb, glove[token].unsqueeze(0)), dim = 0)\n",
        "\n",
        "    return emb"
      ],
      "metadata": {
        "id": "p90qrR6jS0yF"
      },
      "execution_count": 132,
      "outputs": []
    }
  ]
}